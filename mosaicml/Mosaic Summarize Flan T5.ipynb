{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "759d9cd6-228d-4477-bd3e-5193ed26c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7703f4-619e-47c7-a283-a9fd7bf02930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfFolder\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc85072-945d-4ce5-a032-f82f32509b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 203037\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 6436\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 6440\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db=load_dataset(\"scientific_papers\",\"arxiv\")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d4ca257-0848-4564-9fdc-a8023da286fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['train']=db['train'].shuffle(seed=42).select(range(10000))\n",
    "db['validation']=db['validation'].shuffle(seed=42).select(range(3000))\n",
    "db['test']=db['test'].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e70c93-b0ae-41de-8b6d-12d245a1d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id='google/flan-t5-small'\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3149797-1c2d-4b71-adc7-f7ef18673039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "data_collator = transformers.data.data_collator.default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9672979-1937-480d-a249-c47390b66df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73920f715eab4701b2eeb794298e3cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def preprocess_data(data):\n",
    "    model_inputs=tokenizer([\"summarize\"+article for article in data['article']],max_length=256,padding='max_length',truncation=True)\n",
    "    labels=tokenizer(data['abstract'],max_length=128,padding='max_length',truncation=True)\n",
    "    model_inputs['labels']=labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "db_train=db['train'].map(preprocess_data,batched=True,remove_columns=['article','abstract','section_names'])\n",
    "db_validation=db['validation'].map(preprocess_data,batched=True,remove_columns=['article','abstract','section_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47695bee-f279-4aad-becf-41591ee3d3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edb42e54-e9f3-445a-95ba-4db6eb0ff76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.data.data_collator.default_data_collator\n",
    "train_loader = DataLoader(db_train, batch_size=16, shuffle=False, drop_last=False, collate_fn=data_collator)\n",
    "eval_loader = DataLoader(db_validation,batch_size=16, shuffle=False, drop_last=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feae1ab4-159a-4362-a648-65c29cc16e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#Convert to composer model\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from composer.models.huggingface import HuggingFaceModel\n",
    "from composer.metrics import LanguageCrossEntropy\n",
    "\n",
    "metrics = [LanguageCrossEntropy()]\n",
    "# Package as a trainer-friendly Composer model\n",
    "composer_model = HuggingFaceModel(model, tokenizer=tokenizer, metrics=metrics,use_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8e5383-c427-49f8-b22f-2c4e5951f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0087986-d951-427e-90a9-e5da0ce2a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "optimizer = AdamW(\n",
    "    params=composer_model.parameters(),\n",
    "    lr=3e-5, betas=(0.9, 0.98),\n",
    "    eps=1e-6, weight_decay=3e-6\n",
    ")\n",
    "linear_lr_decay = LinearLR(\n",
    "    optimizer, start_factor=1.0,\n",
    "    end_factor=0, total_iters=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153e16f-4f24-4209-902c-306861e71f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from composer import Trainer\n",
    "\n",
    "# Create Trainer Object\n",
    "trainer = Trainer(\n",
    "    model=composer_model, # This is the model from the HuggingFaceModel wrapper class.\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=eval_loader,\n",
    "    max_duration=\"1ep\",\n",
    "    optimizers=optimizer,\n",
    "    schedulers=[linear_lr_decay],\n",
    "    device='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    train_subset_num_batches=150,\n",
    "    precision='fp32',\n",
    "    seed=17,\n",
    "    \n",
    ")\n",
    "# Start training\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594ec7fd-1401-465d-9324-6c86ad9d9936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval': {'LanguageCrossEntropy': LanguageCrossEntropy(\n",
       "    (loss_fn): CrossEntropyLoss()\n",
       "  )}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c594399-eba2-4595-9dac-32067db1d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch = next(iter(eval_loader))\n",
    "\n",
    "# Move batch to gpu\n",
    "eval_batch = {k: v.cuda() if torch.cuda.is_available() else v for k, v in eval_batch.items()}\n",
    "with torch.no_grad():\n",
    "    predictions = composer_model(eval_batch)[\"logits\"].argmax(dim=1)\n",
    "\n",
    "# Visualize only 5 samples\n",
    "predictions = predictions[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a6f8bb8-6b1c-4964-8190-e68883cd4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.state.model.state_dict(), 'mosaic_summarize.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdd108-000f-43d6-b2e1-9623aec0729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# load model and tokenizer from huggingface hub with pipeline\n",
    "summarizer=pipeline('summarization',model=model,device='cuda',tokenizer=tokenizer)\n",
    "# select a random test sample\n",
    "sample=db['test'][10]['article']\n",
    "print(f\"article: \\n{sample}\\n\\n\\n\")\n",
    "# summarize dialogue\n",
    "res = summarizer(sample)\n",
    "print(\"..................................................Summarize Text..................................\")\n",
    "print(f\"flan-t5-base summary:\\n{res[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c569a-da00-4a4b-9a74-82ecc99b69b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newkernel",
   "language": "python",
   "name": "newgalaxie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
